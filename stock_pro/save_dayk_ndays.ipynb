{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######只保留最近 N 天的数据，仅做最近的数据更新 ###########\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 全局变量设置\n",
    "ndays = 100 ##########设置N的值  n 必须大于34 \n",
    "testdays = 10 ############### 用来测试的天数\n",
    "window_size = [3,5,7,10,13,15,20,23,30,33,60]  ######### 股票均线窗口\n",
    "table_name = 'stocks_dayk_0214'\n",
    "engine = create_engine('mysql+pymysql://root:root@localhost:3306/stock_db')\n",
    "dayk_path = '../../dayk0214/'\n",
    "dayk_files = os.listdir(dayk_path) ###所有日线文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.34568916 -0.39761952 -0.36895151  0.18298564  0.22012321]\n",
      " [ 0.6512361   0.30811992  0.70748409  0.7521524   0.69250487]\n",
      " [ 0.65033359  0.12667135 -0.40824255  0.01894104  0.52506097]\n",
      " [-0.26915649  0.65776578 -0.37557301 -0.43505377 -0.41079509]\n",
      " [ 0.60789932 -0.01223864  0.75280235 -0.55486255  0.21063504]\n",
      " [ 0.8430385  -0.26934826  0.48541187 -0.36782322 -0.55288571]\n",
      " [ 0.31965278 -0.26678083  1.0931587   0.49483582 -0.41324585]\n",
      " [-0.18518757  0.4086632   0.03251826  0.21215643  0.95754536]\n",
      " [ 1.02946548  0.6753408  -0.76456811  0.56998663 -0.5747292 ]\n",
      " [-0.55848459 -0.83179334 -0.60981968 -0.51582332  0.5605415 ]]\n",
      "[[-1.8091239 ]\n",
      " [-0.60163411]\n",
      " [ 0.32494214]\n",
      " [ 0.50816237]\n",
      " [ 0.6530264 ]\n",
      " [ 1.16931438]\n",
      " [ 1.5630337 ]\n",
      " [ 0.60988067]\n",
      " [ 0.19571519]\n",
      " [ 1.33376621]]\n"
     ]
    }
   ],
   "source": [
    "#################读取w1 与w2##################################\n",
    "w1 = np.loadtxt(\"init_w1_30.txt\",delimiter=',')\n",
    "w2 = np.loadtxt(\"init_w2_30.txt\",delimiter=',')\n",
    "w2 = w2.reshape(-1,1)\n",
    "#################根据文件内容，初始化w1与w2#####################\n",
    "\n",
    "######### 设置学习率 \n",
    "n = 0.5\n",
    "######### 样本个数 ###########\n",
    "#print(w2[0:10,:])\n",
    "print(w1[0:10,0:5])\n",
    "print(w2[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select a.code,a.captial from stock_info a \n",
      "--------------------done--------------------------\n"
     ]
    }
   ],
   "source": [
    "############# 股票信息表，查询股票股本等信息 ################\n",
    "sql_stock_info = 'select a.code,a.captial from stock_info a '\n",
    "print(sql_stock_info)\n",
    "df_stock_info = pd.read_sql_query(sql_stock_info,engine)\n",
    "print('--------------------done--------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_stock_info = pd.Series(df_stock_info['captial'].values,index=df_stock_info['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmond(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def reLu(x):\n",
    "    return (np.abs(x)+x) / 2.0\n",
    "\n",
    "def d_reLu(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>1] = 1\n",
    "    return x\n",
    "\n",
    "def softmax(x):\n",
    "    x_row_max = x.max(axis=1).reshape(x.shape[0],1)\n",
    "    x = x - x_row_max\n",
    "    x_exp = np.exp(x)\n",
    "    x_row_exp_sum = x_exp.sum(axis=1).reshape(x.shape[0],1)\n",
    "    x_softmax = x_exp / x_row_exp_sum\n",
    "    return x_softmax\n",
    "\n",
    "def softmax_vector(x):\n",
    "    x_exp = np.exp(x-x.max())\n",
    "    return x_exp / x_exp.sum()\n",
    "\n",
    "######### m 为样本个数 ###############\n",
    "def J_sigmond(h,y,m):\n",
    "    J = -y*np.log(h) - (1-y)*np.log(1-h)\n",
    "    return J.sum() / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# 多空交叉函数 ##############\n",
    "def cross_np(var1,var2):\n",
    "    np_duo_kong = np.zeros(len(var1))\n",
    "    for i in range(1,len(var1)):\n",
    "        if var1[i-1]<var2[i-1] and var1[i] > var2[i] :\n",
    "            np_duo_kong[i]=2\n",
    "        elif var1[i-1]>var2[i-1] and var1[i]<var2[i] :\n",
    "            np_duo_kong[i]=-1\n",
    "        else:\n",
    "            np_duo_kong[i]=0\n",
    "    return np_duo_kong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_train_data (code,duokong,index,date,df_dayk):\n",
    "    i = 0\n",
    "    index_count = len(date)\n",
    "    #file = open('stock_data_lable_normal_30.txt','a+')\n",
    "    data_count = 0\n",
    "    lab_count = 0\n",
    "    while(i < index_count -2 ):\n",
    "        #print('-------- duokong ---------',duokong[i ],date[i])\n",
    "        if duokong[i] == 2:   ##### 如果出现了  多\n",
    "            \n",
    "            #### 判断接下来 n 天，有没有出现 空\n",
    "            start_index = index[i ] ##当前出现 多的 行号\n",
    "            end_index = index[i +1] ##下一次出现空的行号\n",
    "            #print('----间隔天数----',end_index - start_index +1)\n",
    "            if end_index - start_index > 5 : #### 连续 6天 没有 空\n",
    "                csv_df = df_dayk.loc[start_index:start_index+5,['open','close','high','low','rise','exchange','ma5','ma10','ma20','ma30','ma60']]\n",
    "                csv_df_u = df_dayk.loc[start_index:start_index+5,['open','close','high','low','rise','exchange','ma5','ma10','ma20','ma30','ma60']]\n",
    "                #print(csv_df)\n",
    "                \n",
    "                csv_df_u['open'] = (csv_df_u['open'] - csv_df_u['open'].mean()) / csv_df_u['open'].std()\n",
    "                csv_df_u['close'] = (csv_df_u['close'] - csv_df_u['close'].mean()) / csv_df_u['close'].std()\n",
    "                csv_df_u['high'] = (csv_df_u['high'] - csv_df_u['high'].mean()) / csv_df_u['high'].std()\n",
    "                csv_df_u['low'] = (csv_df_u['low'] - csv_df_u['low'].mean()) / csv_df_u['low'].std()\n",
    "                csv_df_u['rise'] = (csv_df_u['rise'] - csv_df_u['rise'].mean()) / csv_df_u['rise'].std()\n",
    "                csv_df_u['exchange'] = (csv_df_u['exchange'] - csv_df_u['exchange'].mean()) / csv_df_u['exchange'].std()\n",
    "                csv_df_u['ma5'] = (csv_df_u['ma5'] - csv_df_u['ma5'].mean()) / csv_df_u['ma5'].std()\n",
    "                csv_df_u['ma10'] = (csv_df_u['ma10'] - csv_df_u['ma10'].mean()) / csv_df_u['ma10'].std()\n",
    "                csv_df_u['ma20'] = (csv_df_u['ma20'] - csv_df_u['ma20'].mean()) / csv_df_u['ma20'].std()\n",
    "                csv_df_u['ma30'] = (csv_df_u['ma30'] - csv_df_u['ma30'].mean()) / csv_df_u['ma30'].std()\n",
    "                csv_df_u['ma60'] = (csv_df_u['ma60'] - csv_df_u['ma60'].mean()) / csv_df_u['ma60'].std()\n",
    "                #csv_df_u.to_csv('stock_data_normal_u_30.csv',mode = 'a',index=False,header=None,float_format='%.5f')\n",
    "                csv_np_u = csv_df_u.values\n",
    "                csv_np_u = csv_np_u.reshape(-1,66)\n",
    "                csv_np_u = np.insert(csv_np_u,0,1,axis=1)\n",
    "                print(csv_np_u.shape)\n",
    "                nn_test(code,date[i],csv_np_u)\n",
    "                '''\n",
    "                csv_df['open'] = (csv_df['open'] - csv_df['open'].min()) / (csv_df['open'].max() - csv_df['open'].min())\n",
    "                csv_df['close'] = (csv_df['close'] - csv_df['close'].min()) / (csv_df['close'].max() - csv_df['close'].min())\n",
    "                csv_df['high'] = (csv_df['high'] - csv_df['high'].min()) / (csv_df['high'].max() - csv_df['high'].min())\n",
    "                csv_df['low'] = (csv_df['low'] - csv_df['low'].min()) / (csv_df['low'].max() - csv_df['low'].min())\n",
    "                csv_df['rise'] = (csv_df['rise'] - csv_df['rise'].min()) / (csv_df['rise'].max() - csv_df['rise'].min())\n",
    "                csv_df['exchange'] = (csv_df['exchange'] - csv_df['exchange'].min()) / (csv_df['exchange'].max() - csv_df['exchange'].min())\n",
    "                csv_df['ma5'] = (csv_df['ma5'] - csv_df['ma5'].min()) / (csv_df['ma5'].max() - csv_df['ma5'].min())\n",
    "                csv_df['ma10'] = (csv_df['ma10'] - csv_df['ma10'].min()) / (csv_df['ma10'].max() - csv_df['ma10'].min())\n",
    "                csv_df['ma20'] = (csv_df['ma20'] - csv_df['ma20'].min()) / (csv_df['ma20'].max() - csv_df['ma20'].min())\n",
    "                csv_df['ma30'] = (csv_df['ma30'] - csv_df['ma30'].min()) / (csv_df['ma30'].max() - csv_df['ma30'].min())\n",
    "                csv_df['ma60'] = (csv_df['ma60'] - csv_df['ma60'].min()) / (csv_df['ma60'].max() - csv_df['ma60'].min())  \n",
    "                '''\n",
    "                #print(csv_df)\n",
    "                #csv_df.to_csv('stock_data_normal_30.csv',mode = 'a',index=False,header=None,float_format='%.5f')\n",
    "                #df_dayk.loc[start_index:start_index+5].to_csv('stock_data.csv',mode = 'a',index=False,header=None)\n",
    "                \n",
    "        i = i+1\n",
    "    #file.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_test(code,date,x_test_data):\n",
    "    \n",
    "    hid_input = np.matmul(x_test_data,w1)\n",
    "    hid_output = np.tanh(hid_input)\n",
    "    hid_output = np.insert(hid_output,0,1,axis=0)\n",
    "    hpfs_input = np.matmul(hid_output,w2)\n",
    "    hpfs_output = sigmond(hpfs_input)\n",
    "    print(code,date,hpfs_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 67)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 201 is different from 200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-6c953b727b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mdf_duo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdayk_df_insert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdayk_df_insert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduokong\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdayk_df_insert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduokong\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mdf_duo_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_duo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mflag_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_duo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'duokong'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_duo_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_duo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdayk_df_insert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;31m#dayk_df_insert.to_sql(table_name,engine,index=False,if_exists='append')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#print(dayk_df.head(5))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-d1b9b7380da8>\u001b[0m in \u001b[0;36mflag_train_data\u001b[0;34m(code, duokong, index, date, df_dayk)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mcsv_np_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_np_u\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_np_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mnn_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcsv_np_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 '''\n\u001b[1;32m     38\u001b[0m                 \u001b[0mcsv_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcsv_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcsv_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcsv_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcsv_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-9a3d5983f7d4>\u001b[0m in \u001b[0;36mnn_test\u001b[0;34m(code, date, x_test_data)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mhid_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhid_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mhpfs_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mhpfs_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhpfs_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhpfs_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 201 is different from 200)"
     ]
    }
   ],
   "source": [
    "### 入库所有通达信 日线文件\n",
    "### DELETE from stocks_dayk where LENGTH(date)>8;\n",
    "for file in dayk_files:\n",
    "    #print(file)\n",
    "    dayk_df = pd.read_csv(dayk_path+file,skiprows=[0,1],sep=';',encoding='ISO-8859-1',header=None)\n",
    "    dayk_df.drop([len(dayk_df)-1],inplace=True)\n",
    "    dayk_df.rename(columns={0:'date',1:'open',2:'high',3:'low',4:'close',5:'vol',6:'money'},inplace=True)\n",
    "    #print('-----',dayk_df.columns)\n",
    "    dayk_df['code'] = file[:-4]\n",
    "    try:\n",
    "        captial = float(se_stock_info[file[:-4]])\n",
    "    except:\n",
    "        continue\n",
    "    #print(captial)\n",
    "    days_count = dayk_df.shape[0]  #### 天数\n",
    "    if days_count>ndays and days_count > 34:\n",
    "        dayk_df['duokong']=pd.DataFrame(np.zeros(days_count))\n",
    "        dayk_df = dayk_df.sort_values(by='date',ascending=True)\n",
    "        #dayk_df = dayk_df.iloc[days_count - ndays:days_count,:]\n",
    "        max_in_21 = dayk_df['high'].rolling(21).max()\n",
    "        low_in_21 = dayk_df['low'].rolling(21).min()\n",
    "        max_in_6 = dayk_df['high'].rolling(6).max()\n",
    "        low_in_6 = dayk_df['low'].rolling(6).min()\n",
    "        var1 = 100 - 90*(max_in_21 - dayk_df['close'])/(max_in_21 - low_in_21)\n",
    "        var2 = 100 - (100*(max_in_6 - dayk_df['close'])/(max_in_6 - low_in_6)).rolling(34).mean()\n",
    "        var3 = var2.rolling(6).mean()\n",
    "        dayk_df['duokong'] = pd.DataFrame(cross_np(var1.values,var3.values))\n",
    "        #dayk_df['rise'] = pd.DataFrame(np.zeros(dayk_df.shape[0]))\n",
    "        dayk_df['rise'] = (dayk_df['close']-dayk_df['close'].shift(1))/dayk_df['close'].shift(1)\n",
    "        dayk_df['rise'] = dayk_df['rise'].round(5)\n",
    "        #print(type(dayk_df[5]))\n",
    "        #print(type(captial))\n",
    "        dayk_df['exchange'] = dayk_df['vol']/captial\n",
    "        dayk_df['exchange'] = dayk_df['exchange']/100000000\n",
    "        dayk_df['exchange'] = dayk_df['exchange'].round(6)\n",
    "        #print(dayk_df)\n",
    "        for i in window_size:\n",
    "            dayk_df['ma'+str(i)] = dayk_df['close'].rolling(i).mean().round(3)\n",
    "        dayk_df_insert = dayk_df.iloc[days_count - testdays:days_count,:]\n",
    "        df_duo = dayk_df_insert[(dayk_df_insert.duokong==2)|(dayk_df_insert.duokong==-1)]\n",
    "        df_duo_index = df_duo.index.tolist()\n",
    "        if df_duo_index[df_duo_index.shape[0] - 1] == 2 :\n",
    "            \n",
    "            flag_train_data(file[:-4],df_duo['duokong'].values,df_duo_index,df_duo['date'].values,dayk_df_insert)\n",
    "        #dayk_df_insert.to_sql(table_name,engine,index=False,if_exists='append')\n",
    "        #print(dayk_df.head(5))\n",
    "        #print(dayk_df.tail(20))\n",
    "        #print('finish insert ',file)\n",
    "print('-------------dataframe to sql is awesome---------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
